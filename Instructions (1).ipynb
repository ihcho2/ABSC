{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5493ca78",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39cf9d",
   "metadata": {},
   "source": [
    "### 1. Install several requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2672db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install tensorboardX\n",
    "!pip install transformers\n",
    "!pip install spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f276a",
   "metadata": {},
   "source": [
    "### 2. Place the BERT model-related files and GloVE word embeddings following the instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae0a4e",
   "metadata": {},
   "source": [
    "* 구글 드라이브 /code 에 있는 uncased_L-12_H-768_A-12.zip 과 glove.840B.300d.zip 을 './ABSC'에 업로드 후 아래 두 코드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cc7f9d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "   creating: uncased_L-12_H-768_A-12/\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3fb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_BASE_DIR='./uncased_L-12_H-768_A-12'\n",
    "\n",
    "!python3 convert_tf_to_pytorch/convert_tf_checkpoint_to_pytorch.py \\\n",
    "  --tf_checkpoint_path $BERT_BASE_DIR/bert_model.ckpt \\\n",
    "  --bert_config_file $BERT_BASE_DIR/bert_config.json \\\n",
    "  --pytorch_dump_path $BERT_BASE_DIR/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00957450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./glove.840B.300d.zip\n",
      "  inflating: ./datasets/glove/glove.840B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip './glove.840B.300d.zip' -d './datasets/glove'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05281753",
   "metadata": {},
   "source": [
    "### 3. Create dependency graphs by running following codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf55ec7",
   "metadata": {},
   "source": [
    "* final output files are f'./{dataset_name}_datas.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df103035",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 08:29:09.633270: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "100%|███████████████████████████████████████| 3608/3608 [01:46<00:00, 33.99it/s]\n",
      "100%|███████████████████████████████████████| 3608/3608 [02:10<00:00, 27.62it/s]\n",
      "100%|███████████████████████████████████████| 1120/1120 [00:40<00:00, 27.86it/s]\n",
      "100%|███████████████████████████████████████| 2328/2328 [01:10<00:00, 33.10it/s]\n",
      "100%|███████████████████████████████████████| 2328/2328 [01:26<00:00, 26.83it/s]\n",
      "100%|█████████████████████████████████████████| 638/638 [00:22<00:00, 28.20it/s]\n"
     ]
    }
   ],
   "source": [
    "!python generateGraph_spacy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74418ca4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 08:47:40.796772: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "preparing twitter dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_twitter_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 6248/6248 [08:55<00:00, 11.67it/s]\n",
      "100%|█████████████████████████████████████████| 692/692 [00:57<00:00, 11.94it/s]\n",
      "preparing rest14 dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_rest14_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 3608/3608 [04:57<00:00, 12.15it/s]\n",
      "100%|███████████████████████████████████████| 1120/1120 [01:31<00:00, 12.29it/s]\n",
      "preparing lap14 dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_lap14_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 2328/2328 [03:16<00:00, 11.88it/s]\n",
      "100%|█████████████████████████████████████████| 638/638 [00:51<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "!python data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011cde45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4f0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "for i in range(10):\n",
    "    var_name = 'seed'+str(i+1)\n",
    "    locals()[var_name] = random.randint(0,10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word_roberta.py \\\n",
    "--model_name roberta_gcls \\\n",
    "--task_name=laptop \\\n",
    "--graph_type 'dg' \\\n",
    "--L_config_base '0,0,0,0,1,1,1,1,2,2,2,2' \\\n",
    "--g_config '1,1,1,1' \\\n",
    "--g_pooler 'att' \\\n",
    "--data_dir=/home/ikhyuncho23/GoBERTa/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/GoBERTa/roberta_files/vocab.json \\\n",
    "--roberta_config_file=/home/ikhyuncho23/GoBERTa/roberta_files/config.json \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 1.5e-5 \\\n",
    "--num_train_epochs 20.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--model_save_path trained_model_ckpts/ \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
