{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5493ca78",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39cf9d",
   "metadata": {},
   "source": [
    "### 1. Install several requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "!pip3 install tensorboardX\n",
    "!pip install transformers\n",
    "!pip install spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f276a",
   "metadata": {},
   "source": [
    "### 2. Place the BERT model-related files and GloVE word embeddings following the instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae0a4e",
   "metadata": {},
   "source": [
    "* 구글 드라이브 /code 에 있는 uncased_L-12_H-768_A-12.zip 과 glove.840B.300d.zip 을 './ABSC'에 업로드 후 아래 두 코드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cc7f9d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "   creating: uncased_L-12_H-768_A-12/\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d52be0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 06:38:36.730316: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Converting TensorFlow checkpoint from ./uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Loading bert/embeddings/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/embeddings/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/embeddings/position_embeddings with shape [512, 768]\n",
      "Numpy array shape (512, 768)\n",
      "Loading bert/embeddings/token_type_embeddings with shape [2, 768]\n",
      "Numpy array shape (2, 768)\n",
      "Loading bert/embeddings/word_embeddings with shape [30522, 768]\n",
      "Numpy array shape (30522, 768)\n",
      "Loading bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
      "Numpy array shape (3072, 768)\n",
      "Loading bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
      "Numpy array shape (768, 768)\n",
      "Loading bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
      "Numpy array shape (3072,)\n",
      "Loading bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
      "Numpy array shape (768, 3072)\n",
      "Loading bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/output/dense/bias with shape [768]\n",
      "Numpy array shape (768,)\n",
      "Loading bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array shape (3072, 768)\r\n",
      "Loading bert/pooler/dense/bias with shape [768]\r\n",
      "Numpy array shape (768,)\r\n",
      "Loading bert/pooler/dense/kernel with shape [768, 768]\r\n",
      "Numpy array shape (768, 768)\r\n",
      "Loading cls/predictions/output_bias with shape [30522]\r\n",
      "Numpy array shape (30522,)\r\n",
      "Loading cls/predictions/transform/LayerNorm/beta with shape [768]\r\n",
      "Numpy array shape (768,)\r\n",
      "Loading cls/predictions/transform/LayerNorm/gamma with shape [768]\r\n",
      "Numpy array shape (768,)\r\n",
      "Loading cls/predictions/transform/dense/bias with shape [768]\r\n",
      "Numpy array shape (768,)\r\n",
      "Loading cls/predictions/transform/dense/kernel with shape [768, 768]\r\n",
      "Numpy array shape (768, 768)\r\n",
      "Loading cls/seq_relationship/output_bias with shape [2]\r\n",
      "Numpy array shape (2,)\r\n",
      "Loading cls/seq_relationship/output_weights with shape [2, 768]\r\n",
      "Numpy array shape (2, 768)\r\n",
      "Loading embeddings/LayerNorm/beta\r\n",
      "Loading embeddings/LayerNorm/gamma\r\n",
      "Loading embeddings/position_embeddings\r\n",
      "Loading embeddings/token_type_embeddings\r\n",
      "Loading embeddings/word_embeddings\r\n",
      "Loading encoder/layer_0/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_0/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_0/attention/output/dense/bias\r\n",
      "Loading encoder/layer_0/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_0/attention/self/key/bias\r\n",
      "Loading encoder/layer_0/attention/self/key/kernel\r\n",
      "Loading encoder/layer_0/attention/self/query/bias\r\n",
      "Loading encoder/layer_0/attention/self/query/kernel\r\n",
      "Loading encoder/layer_0/attention/self/value/bias\r\n",
      "Loading encoder/layer_0/attention/self/value/kernel\r\n",
      "Loading encoder/layer_0/intermediate/dense/bias\r\n",
      "Loading encoder/layer_0/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_0/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_0/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_0/output/dense/bias\r\n",
      "Loading encoder/layer_0/output/dense/kernel\r\n",
      "Loading encoder/layer_1/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_1/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_1/attention/output/dense/bias\r\n",
      "Loading encoder/layer_1/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_1/attention/self/key/bias\r\n",
      "Loading encoder/layer_1/attention/self/key/kernel\r\n",
      "Loading encoder/layer_1/attention/self/query/bias\r\n",
      "Loading encoder/layer_1/attention/self/query/kernel\r\n",
      "Loading encoder/layer_1/attention/self/value/bias\r\n",
      "Loading encoder/layer_1/attention/self/value/kernel\r\n",
      "Loading encoder/layer_1/intermediate/dense/bias\r\n",
      "Loading encoder/layer_1/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_1/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_1/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_1/output/dense/bias\r\n",
      "Loading encoder/layer_1/output/dense/kernel\r\n",
      "Loading encoder/layer_10/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_10/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_10/attention/output/dense/bias\r\n",
      "Loading encoder/layer_10/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_10/attention/self/key/bias\r\n",
      "Loading encoder/layer_10/attention/self/key/kernel\r\n",
      "Loading encoder/layer_10/attention/self/query/bias\r\n",
      "Loading encoder/layer_10/attention/self/query/kernel\r\n",
      "Loading encoder/layer_10/attention/self/value/bias\r\n",
      "Loading encoder/layer_10/attention/self/value/kernel\r\n",
      "Loading encoder/layer_10/intermediate/dense/bias\r\n",
      "Loading encoder/layer_10/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_10/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_10/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_10/output/dense/bias\r\n",
      "Loading encoder/layer_10/output/dense/kernel\r\n",
      "Loading encoder/layer_11/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_11/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_11/attention/output/dense/bias\r\n",
      "Loading encoder/layer_11/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_11/attention/self/key/bias\r\n",
      "Loading encoder/layer_11/attention/self/key/kernel\r\n",
      "Loading encoder/layer_11/attention/self/query/bias\r\n",
      "Loading encoder/layer_11/attention/self/query/kernel\r\n",
      "Loading encoder/layer_11/attention/self/value/bias\r\n",
      "Loading encoder/layer_11/attention/self/value/kernel\r\n",
      "Loading encoder/layer_11/intermediate/dense/bias\r\n",
      "Loading encoder/layer_11/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_11/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_11/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_11/output/dense/bias\r\n",
      "Loading encoder/layer_11/output/dense/kernel\r\n",
      "Loading encoder/layer_2/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_2/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_2/attention/output/dense/bias\r\n",
      "Loading encoder/layer_2/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_2/attention/self/key/bias\r\n",
      "Loading encoder/layer_2/attention/self/key/kernel\r\n",
      "Loading encoder/layer_2/attention/self/query/bias\r\n",
      "Loading encoder/layer_2/attention/self/query/kernel\r\n",
      "Loading encoder/layer_2/attention/self/value/bias\r\n",
      "Loading encoder/layer_2/attention/self/value/kernel\r\n",
      "Loading encoder/layer_2/intermediate/dense/bias\r\n",
      "Loading encoder/layer_2/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_2/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_2/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_2/output/dense/bias\r\n",
      "Loading encoder/layer_2/output/dense/kernel\r\n",
      "Loading encoder/layer_3/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_3/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_3/attention/output/dense/bias\r\n",
      "Loading encoder/layer_3/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_3/attention/self/key/bias\r\n",
      "Loading encoder/layer_3/attention/self/key/kernel\r\n",
      "Loading encoder/layer_3/attention/self/query/bias\r\n",
      "Loading encoder/layer_3/attention/self/query/kernel\r\n",
      "Loading encoder/layer_3/attention/self/value/bias\r\n",
      "Loading encoder/layer_3/attention/self/value/kernel\r\n",
      "Loading encoder/layer_3/intermediate/dense/bias\r\n",
      "Loading encoder/layer_3/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_3/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_3/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_3/output/dense/bias\r\n",
      "Loading encoder/layer_3/output/dense/kernel\r\n",
      "Loading encoder/layer_4/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_4/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_4/attention/output/dense/bias\r\n",
      "Loading encoder/layer_4/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_4/attention/self/key/bias\r\n",
      "Loading encoder/layer_4/attention/self/key/kernel\r\n",
      "Loading encoder/layer_4/attention/self/query/bias\r\n",
      "Loading encoder/layer_4/attention/self/query/kernel\r\n",
      "Loading encoder/layer_4/attention/self/value/bias\r\n",
      "Loading encoder/layer_4/attention/self/value/kernel\r\n",
      "Loading encoder/layer_4/intermediate/dense/bias\r\n",
      "Loading encoder/layer_4/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_4/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_4/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_4/output/dense/bias\r\n",
      "Loading encoder/layer_4/output/dense/kernel\r\n",
      "Loading encoder/layer_5/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_5/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_5/attention/output/dense/bias\r\n",
      "Loading encoder/layer_5/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_5/attention/self/key/bias\r\n",
      "Loading encoder/layer_5/attention/self/key/kernel\r\n",
      "Loading encoder/layer_5/attention/self/query/bias\r\n",
      "Loading encoder/layer_5/attention/self/query/kernel\r\n",
      "Loading encoder/layer_5/attention/self/value/bias\r\n",
      "Loading encoder/layer_5/attention/self/value/kernel\r\n",
      "Loading encoder/layer_5/intermediate/dense/bias\r\n",
      "Loading encoder/layer_5/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_5/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_5/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_5/output/dense/bias\r\n",
      "Loading encoder/layer_5/output/dense/kernel\r\n",
      "Loading encoder/layer_6/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_6/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_6/attention/output/dense/bias\r\n",
      "Loading encoder/layer_6/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_6/attention/self/key/bias\r\n",
      "Loading encoder/layer_6/attention/self/key/kernel\r\n",
      "Loading encoder/layer_6/attention/self/query/bias\r\n",
      "Loading encoder/layer_6/attention/self/query/kernel\r\n",
      "Loading encoder/layer_6/attention/self/value/bias\r\n",
      "Loading encoder/layer_6/attention/self/value/kernel\r\n",
      "Loading encoder/layer_6/intermediate/dense/bias\r\n",
      "Loading encoder/layer_6/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_6/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_6/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_6/output/dense/bias\r\n",
      "Loading encoder/layer_6/output/dense/kernel\r\n",
      "Loading encoder/layer_7/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_7/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_7/attention/output/dense/bias\r\n",
      "Loading encoder/layer_7/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_7/attention/self/key/bias\r\n",
      "Loading encoder/layer_7/attention/self/key/kernel\r\n",
      "Loading encoder/layer_7/attention/self/query/bias\r\n",
      "Loading encoder/layer_7/attention/self/query/kernel\r\n",
      "Loading encoder/layer_7/attention/self/value/bias\r\n",
      "Loading encoder/layer_7/attention/self/value/kernel\r\n",
      "Loading encoder/layer_7/intermediate/dense/bias\r\n",
      "Loading encoder/layer_7/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_7/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_7/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_7/output/dense/bias\r\n",
      "Loading encoder/layer_7/output/dense/kernel\r\n",
      "Loading encoder/layer_8/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_8/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_8/attention/output/dense/bias\r\n",
      "Loading encoder/layer_8/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_8/attention/self/key/bias\r\n",
      "Loading encoder/layer_8/attention/self/key/kernel\r\n",
      "Loading encoder/layer_8/attention/self/query/bias\r\n",
      "Loading encoder/layer_8/attention/self/query/kernel\r\n",
      "Loading encoder/layer_8/attention/self/value/bias\r\n",
      "Loading encoder/layer_8/attention/self/value/kernel\r\n",
      "Loading encoder/layer_8/intermediate/dense/bias\r\n",
      "Loading encoder/layer_8/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_8/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_8/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_8/output/dense/bias\r\n",
      "Loading encoder/layer_8/output/dense/kernel\r\n",
      "Loading encoder/layer_9/attention/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_9/attention/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_9/attention/output/dense/bias\r\n",
      "Loading encoder/layer_9/attention/output/dense/kernel\r\n",
      "Loading encoder/layer_9/attention/self/key/bias\r\n",
      "Loading encoder/layer_9/attention/self/key/kernel\r\n",
      "Loading encoder/layer_9/attention/self/query/bias\r\n",
      "Loading encoder/layer_9/attention/self/query/kernel\r\n",
      "Loading encoder/layer_9/attention/self/value/bias\r\n",
      "Loading encoder/layer_9/attention/self/value/kernel\r\n",
      "Loading encoder/layer_9/intermediate/dense/bias\r\n",
      "Loading encoder/layer_9/intermediate/dense/kernel\r\n",
      "Loading encoder/layer_9/output/LayerNorm/beta\r\n",
      "Loading encoder/layer_9/output/LayerNorm/gamma\r\n",
      "Loading encoder/layer_9/output/dense/bias\r\n",
      "Loading encoder/layer_9/output/dense/kernel\r\n",
      "Loading pooler/dense/bias\r\n",
      "Loading pooler/dense/kernel\r\n",
      "Loading redictions/output_bias\r\n",
      "Skipping\r\n",
      "Loading redictions/transform/LayerNorm/beta\r\n",
      "Skipping\r\n",
      "Loading redictions/transform/LayerNorm/gamma\r\n",
      "Skipping\r\n",
      "Loading redictions/transform/dense/bias\r\n",
      "Skipping\r\n",
      "Loading redictions/transform/dense/kernel\r\n",
      "Skipping\r\n",
      "Loading eq_relationship/output_bias\r\n",
      "Skipping\r\n",
      "Loading eq_relationship/output_weights\r\n",
      "Skipping\r\n"
     ]
    }
   ],
   "source": [
    "BERT_BASE_DIR='./uncased_L-12_H-768_A-12'\n",
    "\n",
    "!python3 convert_tf_to_pytorch/convert_tf_checkpoint_to_pytorch.py \\\n",
    "  --tf_checkpoint_path $BERT_BASE_DIR/bert_model.ckpt \\\n",
    "  --bert_config_file $BERT_BASE_DIR/bert_config.json \\\n",
    "  --pytorch_dump_path $BERT_BASE_DIR/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00957450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./glove.840B.300d.zip\n",
      "  inflating: ./datasets/glove/glove.840B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip './glove.840B.300d.zip' -d './datasets/glove'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05281753",
   "metadata": {},
   "source": [
    "### 3. Create dependency graphs by running following codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf55ec7",
   "metadata": {},
   "source": [
    "* final output files are f'./{dataset_name}_datas.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df103035",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 08:29:09.633270: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "100%|███████████████████████████████████████| 3608/3608 [01:46<00:00, 33.99it/s]\n",
      "100%|███████████████████████████████████████| 3608/3608 [02:10<00:00, 27.62it/s]\n",
      "100%|███████████████████████████████████████| 1120/1120 [00:40<00:00, 27.86it/s]\n",
      "100%|███████████████████████████████████████| 2328/2328 [01:10<00:00, 33.10it/s]\n",
      "100%|███████████████████████████████████████| 2328/2328 [01:26<00:00, 26.83it/s]\n",
      "100%|█████████████████████████████████████████| 638/638 [00:22<00:00, 28.20it/s]\n"
     ]
    }
   ],
   "source": [
    "!python generateGraph_spacy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74418ca4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 08:47:40.796772: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "preparing twitter dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_twitter_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 6248/6248 [08:55<00:00, 11.67it/s]\n",
      "100%|█████████████████████████████████████████| 692/692 [00:57<00:00, 11.94it/s]\n",
      "preparing rest14 dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_rest14_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 3608/3608 [04:57<00:00, 12.15it/s]\n",
      "100%|███████████████████████████████████████| 1120/1120 [01:31<00:00, 12.29it/s]\n",
      "preparing lap14 dataset ...\n",
      "load successfully\n",
      "loading word vectors ...\n",
      "building embedding_matrix: 300_lap14_embedding_matrix.pkl\n",
      "100%|███████████████████████████████████████| 2328/2328 [03:16<00:00, 11.88it/s]\n",
      "100%|█████████████████████████████████████████| 638/638 [00:51<00:00, 12.51it/s]\n"
     ]
    }
   ],
   "source": [
    "!python data_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7dc43",
   "metadata": {},
   "source": [
    "### 4. Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d8ec4",
   "metadata": {},
   "source": [
    "model_name:\n",
    "\n",
    "    1. Baseline models \n",
    "    * td_bert: our BERT-baseline model which is identical to TD-BERT.\n",
    "    * td_bert_with_gcn: our [BERT + GCN] baseline model 1. Simple concatenation of TD-BERT and GCN.\n",
    "    * td_bert_with_bigcn: our [BERT + GCN] baseline model 2. Using BiGCN instead of GCN  \n",
    "    * GCN: GCN baseline model similar to CDT. \n",
    "    * BiGCN: BiGCN baseline model similar to CDT but using BiGCN instead of GCN.\n",
    "    \n",
    "    2. Proposed models \n",
    "    * td_bert_with_bigcn_with_appendix:\n",
    "    * td_bert_with_bigcn_with_appendix_with_multiview: \n",
    "    \n",
    "    * td_bert_with_moe:\n",
    "    * td_bert_with_moe_with_IDEA1: \n",
    "    \n",
    "    * dual_cls_bert: \n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3960c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "for i in range(10):\n",
    "    var_name = 'seed'+str(i+1)\n",
    "    locals()[var_name] = random.randint(0,10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa09bf8",
   "metadata": {},
   "source": [
    "## 1. td_bert - Lap14 (이것만 20개 random seed로 해봄)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb00ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88731b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b96066",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822aa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db903f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6758b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c600ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55430129",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613b93c",
   "metadata": {},
   "source": [
    "## 2. td_bert_with_gcn - lap 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46104d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd650eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeac0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac144275",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90176391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d319c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=laptop \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/laptops/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78692508",
   "metadata": {},
   "source": [
    "## 1. td_bert - Rest 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac705969",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983457c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3759505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac696a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb05bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039785c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc16a35",
   "metadata": {},
   "source": [
    "## 2. td_bert_with_gcn - Rest14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21493d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ef008",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c95304",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81cf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_classifier_word.py \\\n",
    "--model_name td_bert_with_gcn \\\n",
    "--task_name=restaurant \\\n",
    "--data_dir=/home/ikhyuncho23/ABSC/datasets/semeval14/restaurants/ \\\n",
    "--vocab_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "--bert_config_file=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "--init_checkpoint=/home/ikhyuncho23/ABSC/uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
    "--max_seq_length=128 \\\n",
    "--train_batch_size 32 \\\n",
    "--eval_batch_size 32 \\\n",
    "--learning_rate 2e-5 \\\n",
    "--num_train_epochs 6.0 \\\n",
    "--local_rank -1 \\\n",
    "--gpu_id 0 \\\n",
    "--output_dir ABSC/log/lap_td_bert_3way_10 \\\n",
    "--para_LSR 0.2 \\\n",
    "--log_step 5 \\\n",
    "--seed $seed10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
